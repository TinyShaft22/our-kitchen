---
phase: 19-muffins-batch
plan: 01
type: execute
---

<objective>
Scrape all 18 muffin recipes from Broma Bakery muffins category.

Purpose: Collect recipe data (ingredients, instructions, yield) for JSON generation.
Output: muffins-index.md with full recipe list, muffins-batch-1.md and muffins-batch-2.md with scraped recipe data.
</objective>

<execution_context>
./.claude/get-shit-done/workflows/execute-phase.md
./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16-scraping-infrastructure/INGREDIENT-MAP.md
@.planning/phases/18-bars-batch/18-01-SUMMARY.md

**Pattern established in Phases 17-18:**
- WebFetch to category page for recipe list
- Create index file with all recipe URLs
- Scrape in batches of 9-12 recipes per batch file
- Extract: title, yield, prep/cook time, ingredients, instructions, URL

**Target:** Broma Bakery Muffins category (expected 18 recipes per roadmap)
**Subcategory:** "Broma/Muffins"
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create muffins category index</name>
  <files>.planning/phases/19-muffins-batch/muffins-index.md</files>
  <action>
    WebFetch https://bromabakery.com/category/recipes/breakfast/muffins/ to get list of muffin recipes.

    Create muffins-index.md with:
    - Recipe count
    - Numbered list of all recipes with URLs
    - Note any pagination if more than one page

    Follow same format as bars-index.md from Phase 18.
  </action>
  <verify>muffins-index.md exists with recipe list and URLs</verify>
  <done>Index file created with all muffin recipe URLs documented</done>
</task>

<task type="auto">
  <name>Task 2: Scrape muffins batch 1 (recipes 1-9)</name>
  <files>.planning/phases/19-muffins-batch/muffins-batch-1.md</files>
  <action>
    WebFetch first 9 recipes from muffins-index.md.

    For each recipe, extract:
    - Title
    - Yield (makes/serves)
    - Prep time, Cook time
    - Full ingredient list with quantities
    - Full instructions
    - Original URL

    Format as markdown with clear sections per recipe.
    Use parallel WebFetch calls for efficiency.
  </action>
  <verify>muffins-batch-1.md exists with 9 complete recipes</verify>
  <done>First batch scraped with all recipe data captured</done>
</task>

<task type="auto">
  <name>Task 3: Scrape muffins batch 2 (recipes 10-18)</name>
  <files>.planning/phases/19-muffins-batch/muffins-batch-2.md</files>
  <action>
    WebFetch remaining recipes from muffins-index.md (recipes 10-18).

    Same extraction format as batch 1:
    - Title, Yield, Times
    - Ingredients, Instructions, URL

    If fewer than 18 total recipes, adjust batch accordingly.
  </action>
  <verify>muffins-batch-2.md exists with remaining recipes</verify>
  <done>All muffin recipes scraped and documented</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] muffins-index.md has complete recipe list with URLs
- [ ] muffins-batch-1.md has first batch of recipes with full data
- [ ] muffins-batch-2.md has remaining recipes with full data
- [ ] All recipes have: title, yield, ingredients, instructions, URL
</verification>

<success_criteria>
- All tasks completed
- All muffin recipes from Broma Bakery scraped
- Recipe data is complete (no missing ingredients or instructions)
- Files ready for JSON generation in 19-02
</success_criteria>

<output>
After completion, create `.planning/phases/19-muffins-batch/19-01-SUMMARY.md` following summary template.
</output>
