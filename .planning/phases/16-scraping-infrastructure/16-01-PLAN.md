---
phase: 16-scraping-infrastructure
plan: 01
type: execute
---

<objective>
Test scrape one Broma Bakery recipe using WebFetch, extract ingredients and instructions, format as import-ready JSON.

Purpose: Validate the scraping approach and JSON format before batch processing 91 recipes.
Output: Working test JSON file that imports successfully into the app.
</objective>

<execution_context>
./.claude/get-shit-done/workflows/execute-phase.md
./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@src/types/index.ts
@src/components/settings/ImportMealsModal.tsx

**Import JSON Format Required:**
```json
{
  "version": 1,
  "meals": [{
    "name": "Recipe Name",
    "servings": 12,
    "isBaking": true,
    "ingredients": [
      { "name": "all-purpose flour", "category": "baking", "defaultStore": "costco", "qty": 2, "unit": "cup" }
    ],
    "instructions": "## Instructions\n\n1. Step one\n2. Step two\n\n---\n[Original recipe](https://bromabakery.com/...)",
    "subcategory": "Broma/Cookies"
  }]
}
```

**Valid categories:** produce, meat, dairy, pantry, frozen, bakery, snacks, beverages, baking
**Valid stores:** costco, trader-joes, safeway, bel-air, walmart, winco
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fetch and analyze a test cookie recipe page</name>
  <files>N/A - research task</files>
  <action>
Use WebFetch to fetch a cookie recipe from Broma Bakery (e.g., https://bromabakery.com/brown-butter-chocolate-chip-cookies/ or similar).

Analyze the page structure to identify:
- Recipe title location
- Ingredients list format (look for structured data, recipe card, or ingredient list)
- Instructions format
- Servings/yield information

Document the extraction patterns needed.
  </action>
  <verify>Recipe content successfully fetched and structure documented</verify>
  <done>Page structure understood, extraction approach defined</done>
</task>

<task type="auto">
  <name>Task 2: Create test import JSON file</name>
  <files>.planning/phases/16-scraping-infrastructure/test-recipe.json</files>
  <action>
Based on the fetched recipe, manually create a properly formatted JSON file:

1. Extract recipe name, servings
2. Parse ingredients into name/qty/unit format
3. Assign each ingredient a category (baking, dairy, pantry, produce)
4. Set defaultStore to "costco" for all (can adjust later)
5. Format instructions as markdown with numbered steps
6. Add original recipe link at bottom of instructions
7. Set subcategory to "Broma/Cookies"
8. Set isBaking: true

Ensure JSON matches the import schema exactly (version: 1, meals array).
  </action>
  <verify>JSON is valid: `cat .planning/phases/16-scraping-infrastructure/test-recipe.json | python3 -m json.tool`</verify>
  <done>Valid JSON file created with one recipe</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Test recipe JSON file ready for import</what-built>
  <how-to-verify>
    1. Open the app at localhost:5173 (or deployed URL)
    2. Go to Settings
    3. Click "Import Meals"
    4. Paste the contents of test-recipe.json
    5. Click "Load Meals" - should show 1 meal with no errors
    6. Import the meal
    7. Navigate to Baking section
    8. Verify recipe appears in Broma/Cookies folder
    9. Open recipe and verify instructions display correctly
  </how-to-verify>
  <resume-signal>Type "approved" if import works, or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Recipe page structure documented
- [ ] test-recipe.json is valid JSON
- [ ] JSON matches import schema (version: 1, meals array)
- [ ] Recipe imports successfully into app
- [ ] Recipe displays correctly in Baking section
</verification>

<success_criteria>
- Test recipe JSON file created
- Import process validated end-to-end
- Extraction patterns documented for batch processing
</success_criteria>

<output>
After completion, create `.planning/phases/16-scraping-infrastructure/16-01-SUMMARY.md`
</output>
